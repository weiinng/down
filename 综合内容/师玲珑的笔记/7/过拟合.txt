概念编辑：
为了得到一致假设而使假设变得过度严格称为过拟合。

定义：
给定一个假设空间H，一个假设h属于H，如果存在其他的假设h’属于H,使得在训练样例上h的错误率比h’小，但在整个实例分布上h’比h的错误率小，那么就说假设h过度拟合训练数据。 [1] 


判断方法:
一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在训练数据外的数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。出现这种现象的主要原因是训练数据中存在噪音或者训练数据太少。 


常见原因：
（1）建模样本选取有误，如样本数量太少，选样方法错误，样本标签错误等，导致选取的样本数据不足以代表预定的分类规则；
（2）样本噪音干扰过大，使得机器将部分噪音认为是特征从而扰乱了预设的分类规则；
（3）假设的模型无法合理存在，或者说是假设成立的条件实际并不成立；
（4）参数太多，模型复杂度过高；
（5）对于决策树模型，如果我们对于其生长没有合理的限制，其自由生长有可能使节点只包含单纯的事件数据(event)或非事件数据(no event)，使其虽然可以完美匹配（拟合）训练数据，但是无法适应其他数据集。
（6）对于神经网络模型：a)对样本数据可能存在分类决策面不唯一，随着学习的进行,，BP算法使权值可能收敛过于复杂的决策面；b)权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征。

解决方法：
（1）在神经网络模型中，可使用权值衰减的方法，即每次迭代过程中以某个小因子降低每个权值。
（2）选取合适的停止训练标准，使对机器的训练在合适的程度；
（3）保留验证数据集，对训练成果进行验证；
（4）获取额外数据进行交叉验证；
（5）正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等。