# 一.Scrapy入门

## 1.创建一个scrapy项目

>scrapy  startproject myScrapy

## 2.生成爬虫

> scrapy genspider utcast 'itcast.cn'

3.提取数据

> 完善spider,使用xpath等方法

4.保存数据

> pipeline中保存数据





# 二.完善spider

```python

class Ppp1Spider(scrapy.Spider):            //定义一个spider类，继承自scrapy.spider
    name = 'ppp_1'            //爬虫名字<爬虫启动的时候使用：scrapy crawl ppp_1>
    allowed_domains = ['baidu.com']          //允许爬取的范围，防止爬虫爬到别的网站
    start_urls = ['http://www.baidu.com/']     //开始爬取的地址

    def parse(self, response):      //数据提起方法，接收下载中间件传来的response
        pass

```



## 1.从选择器中提取字符串

### extract()

返回一个包含有字符串数据的列表

### extract_first()

返回列表中的第一个字符串

## 2.注意

1. spider中的parse方法名不能修改
2. 需要爬取url地址必须要属于allow_domain下的链接
3. response.xpath() 返回的是一个包含有selector对象的列表



























