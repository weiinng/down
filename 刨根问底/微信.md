# 递归算法的本质

递归算法本质原理的第一步是分治，把复杂的大的问题，给拆分成一个一个小问题，直到不能再拆解，通过退出条件retrun，然后再从最小的问题开始解决，只到所有的子问题解决完毕，那么最终的大问题就迎刃而解。上面的打印信息，符合栈数据结构的定义，先进后出，通过把所有的子问题压栈之后，然后再一个个出栈，从最简单的步骤计算，最终解决大问题，非常形象。核心思想是分治策略。

# 垃圾回收机制如何解决循环引用

引用计数：是一种垃圾收集机制，而且也是一种最直观，最简单的垃圾收集技术, 当一个对象的引用被创建或者复制时，对象的引用计数加 1；当一个对象的引用被销毁时，对象的引用计数减 1；当对象的引用计数减少为 0 时，就意味着对象已经没有被任何人使用了，可以将其所占用的内存释放了。虽然引用计数必须在每次分配和释放内存的时候加入管理引用计数的动作，然而与其他主流的垃圾收集技术相比，引用计数有一个最大的有点，即“实时性”，任何内存，一旦没有指向它的引用，就会立即被回收。而其他的垃圾收集计数必须在	某种特殊条件下（比如内存分配失败）才能进行无效内存的回收。引用计数机制执行效率问题：引用计数机制所带来的维护引用计数的额外操作与 Python 运行中所
进行的内存分配和释放，引用赋值的次数是成正比的。而这点相比其他主流的垃圾回收机制，比如“标记-清除”，“停止-复制”，是一个弱点，因为这些技术所带来的额外操作基本上只是与待回收的内存数量有关。
如果说执行效率还仅仅是引用计数机制的一个软肋的话，那么很不幸，引用计数机制还存在着一个致命的弱点，正是由于这个弱点，使得侠义的垃圾收集从来没有将引用计数包含在内，能引发出这个致命的弱点就是循环引用（也称交叉引用）。
问题说明：
循环引用可以使一组对象的引用计数不为 0，然而这些对象实际上并没有被任何外部对象所引用， 它们之间只是相互引用。这意味着不会再有人使用这组对象，应该回收这组对象所占用的内存空间，然后由于相互引用的存在，每一个对象的引用计数都不为 0，因此这些对象所占用的内存永远不会被释放。比如：这一点是致命的，这与手动进行内存管理所产生的内存泄露毫无区别。
要解决这个问题，Python 引入了其他的垃圾收集机制来弥补引用计数的缺陷：“标记-清除”，“分代回收”两种收集技术。

标记-清除：标记-清除”是为了解决循环引用的问题。可以包含其他对象引用的容器对象（比如：list，
set，dict，class，instance）都可能产生循环引用。
我们必须承认一个事实，如果两个对象的引用计数都为 1，但是仅仅存在他们之间的循环引用，那么这两个对象都是需要被回收的，也就是说，它们的引用计数虽然表现为非 0，但实际上有效的引用计数为 0。我们必须先将循环引用摘掉，那么这两个对象的有效计数就现身了。假设两个对象为 A、B， 我们从 A 出发，因为它有一个对 B 的引用，则将 B 的引用计数减 1；然后顺着引用达到 B，因为 B 有一个对 A 的引用，同样将 A 的引用减 1，这样，就完成了循环引用对象间环摘除。
但是这样就有一个问题，假设对象 A 有一个对象引用 C，而 C 没有引用 A，如果将 C 计数引用减 1， 而最后 A 并没有被回收，显然，我们错误的将 C 的引用计数减 1，这将导致在未来的某个时刻出现一个对 C 的悬空引用。这就要求我们必须在 A 没有被删除的情况下复原 C 的引用计数，如果采用这样的方案，那么维护引用计数的复杂度将成倍增加。
原理：“标记-清除”采用了更好的做法，我们并不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。
这个计数副本的唯一作用是寻找 root object 集合（该集合中的对象是不能被回收的）。当成功寻找到 root object 集合之后，首先将现在的内存链表一分为二，一条链表中维护 root object 集合，成为 root 链表，而另外一条链表中维护剩下的对象，成为 unreachable 链表。之所以要剖成两个链表， 是基于这样的一种考虑：现在的 unreachable 可能存在被 root 链表中的对象，直接或间接引用的对象， 这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就将其从 unreachable 链表中移到
root 链表中；当完成标记后，unreachable 链表中剩下的所有对象就是名副其实的垃圾对象了，接下来的垃圾回收只需限制在 unreachable 链表中即可。

分代回收 背景：分代的垃圾收集技术是在上个世纪 80 年代初发展起来的一种垃圾收集机制，一系列的研究表明：无论使用何种语言开发，无论开发的是何种类型，何种规模的程序，都存在这样一点相同之处。即：一定比例的内存块的生存周期都比较短，通常是几百万条机器指令的时间，而剩下的内存块，起生存周期比较长，甚至会从程序开始一直持续到程序结束。
从前面“标记-清除”这样的垃圾收集机制来看，这种垃圾收集机制所带来的额外操作实际上与系统中总的内存块的数量是相关的，当需要回收的内存块越多时，垃圾检测带来的额外操作就越多，而垃圾回收带来的额外操作就越少；反之，当需回收的内存块越少时，垃圾检测就将比垃圾回收带来更少的额外操作。为了提高垃圾收集的效率，采用“空间换时间的策略”。
原理：将系统中

# docker命名空间

悦哥 docker文档中提到的namespace 和cgroups                                                         namespace即“命名空间”，也称“名称空间” 、”名字空间”。VS.NET中的各种语言使用的一种代码组织的形式 通过名称空间来分类，区别不同的代码功能 同时也是VS.NET中所有类的完全名称的一部分。                                                                            命名空间是用来组织和重用代码的。如同名字一样的意思，NameSpace（名字空间），之所以出来这样一个东西，是因为人类可用的单词数太少，并且不同的人写的程序不可能所有的变量都没有重名现象，对于库来说，这个问题尤其严重，如果两个人写的库文件中出现同名的变量或函数(不可避免)，使用起来就有问题了。为了解决这个问题，引入了名字空间这个概念，通过使用 namespace xxx；你所使用的库函数或变量就是在该名字空间中定义的，这样一来就不会引起不必要的冲突了。
通常来说，命名空间是唯一识别的一套名字，这样当对象来自不同的地方但是名字相同的时候就不会含糊不清了。使用扩展标记语言的时候，XML的命名空间是所有元素类别和属性的集合。元素类别和属性的名字是可以通过唯一XML命名空间来唯一。
在XML里，任何元素类别或者属性因此分为两部分名字，一个是命名空间里的名字另一个是它的本地名。在XML里，命名空间通常是一个统一资源识别符（URI）的名字。而URI只当名字用。主要目的是为了避免名字的冲突。
cgroups，其名称源自控制组群（control groups）的简写，是Linux内核的一个功能，用来限制、控制与分离一个进程组的资源（如CPU、内存、磁盘输入输出等）。
这个项目最早是由Google的工程师（主要是Paul Menage和Rohit Seth）在2006年发起，最早的名称为进程容器（process containers）。在2007年时，因为在Linux内核中，容器（container）这个名词有许多不同的意义，为避免混乱，被重命名为cgroup，并且被合并到2.6.24版的内核中去。自那以后，又添加了很多功能。
cgroups的一个设计目标是为不同的应用情况提供统一的接口，从控制单一进程（像nice）到操作系统层虚拟化（像OpenVZ，Linux-VServer，LXC）。cgroups提供：
资源限制：组可以被设置不超过设定的内存限制；这也包括虚拟内存。
优先级：一些组可能会得到大量的CPU或磁盘IO吞吐量。
结算：用来衡量系统确实把多少资源用到适合的目的上。
控制：冻结组或检查点和重启动。
 还有 之前提到的OA系统                                                                                                              办公自动化（Office Automation，简称OA），是将计算机、通信等现代化技术运用到传统办公方式，进而形成的一种新型办公方式。办公自动化利用现代化设备和信息化技术，代替办公人员传统的部分手动或重复性业务活动，优质而高效地处理办公事务和业务信息，实现对信息资源的高效利用，进而达到提高生产率、辅助决策的目的，最大限度地提高工作效率和质量、改善工作环境。                                                                                                                                                                                  办公自动化（OA），英文Office Automation的缩写。它可以通过特定流程或特定环节与日常事务联系在一起，使公文在流转、审批、发布等方面提高效率，实现办公管理规范化和信息规范化，降低企业运行成本。 [1] 
办公自动化（OA）是一个企业除了生产控制之外的一切信息处理与管理的集合。不同的使用对象具有不同的功能：对企业高层领导来说，办公自动化（OA）是决策支持系统（DSS）。它运用科学的数学模型，结合企业内部/外部的信息，为企业领导的决策提供参考和依据；对于企业中层管理者来说，办公自动化（OA）是信息管理系统（IMS），它利用业务各环节提供的基础“数据”，提炼出有用的管理“信息”，把握业务进程，降低经营风险，提高经营效率；对于企业普通员工来说，办公自动化（OA）是事务/业务处理系统。办公自动化（OA）为办公室人员提供良好的办公手段和环境，使之准确、高效

# HTTP状态码

Http状态码
2开头 （请求成功）表示成功处理了请求的状态代码。
200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。
201 （已创建） 请求成功并且服务器创建了新的资源。
202 （已接受） 服务器已接受请求，但尚未处理。
203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。
204 （无内容） 服务器成功处理了请求，但没有返回任何内容。
205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。
206 （部分内容） 服务器成功处理了部分 GET 请求。
3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。
300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。
301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。
302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。
304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。
305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。
307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。
400 （错误请求） 服务器不理解请求的语法。
401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。
403 （禁止） 服务器拒绝请求。
404 （未找到） 服务器找不到请求的网页。
405 （方法禁用） 禁用请求中指定的方法。
406 （不接受） 无法使用请求的内容特性响应请求的网页。
407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。
408 （请求超时） 服务器等候请求时发生超时。
409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。
410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。
411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。
412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。
413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。
414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。
415 （不支持的媒体类型） 请求的格式不受请求页面的支持。
416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。
417 （未满足期望值） 服务器未满足"期望"请求标头字段的要求。
5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。
500 （服务器内部错误） 服务器遇到错误，无法完成请求。
501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。
502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。
503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。
504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。
505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。

# 负载均衡的五种策略

负载均衡的5种策略
1.轮询（默认）
每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 

2、指定权重

指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 

3、IP绑定 ip_hash

每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。

4、fair（第三方）

按后端服务器的响应时间来分配请求，响应时间短的优先分配。 

5、url_hash（第三方）

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 

# 各种知识点

(redis缓存)（将radis在mysql之前set， ）
redis现在已经4.0了功能方面非常强大，redis的问题在超高负载的存数据的时候就挡住mysql缓存就变成缓冲，这是一台服务器就不够用了（一台服务器最多16G）超高负载（qps上万的时候，uv上千万）如果一台机器承受不住。。。。。这个时候redis集群就上线了，就是将redis部署到多台服务器上，redis和mysql不同的是mysql就单进程排队模式，redis是随时get出来（因为存储结构是key，value形式的），所以要需要逻辑的 一台（master）主机另一台（slave）从机，每一台的端口号不一样（6379,6380,6381）从机可以无限扩展，但是有一个问题就是master待机了，那就废了，所有的操作就去读mysql去，mysql也扛不住。。。。。
这是时候redis-sentinel（哨兵模式）出现了，官方提出一套解决方案，可以起两个哨兵实例进行监控master和slave读写同步是否正常，（心跳机制）他们之间是以微弱的二进制流来进行传递交互的，一旦发现master宕机了就自动切换，
其实这就是所谓的高负载高可用架构（至少要有3台服务器），在使用集群承担高负载的同时，也能进行高可用的容灾机制。





（redisearch全文检索是高性能因为redis是基于内存的，所有读取写入最快的东西都是基于内存的 ）
原来的全文检索用的是like模糊查询（不能准确命中索引），不能命中索引就要全表查询，如果数据量大的情况这样性能上就大大减低了，
当数据量大，并发高的时候这时候全文检索就出现了，全文检索基于hashmap就是key，value形式的就是散列表，先建好索引，然后依赖索引把数据录进去，搜的时候直接搜索引，因为存在硬盘所以快，性能高，
传统需要编译安装特别麻烦，
但docker里面有redisearch的镜像，直接pull下来就能用了，
然后启动一下docker后台的容器，redis服务映射到宿主的端口是6666，然后在宿主上连接一下，输入下module list如果返回的数组里有‘ft’就说明成功加载了





传统client发送二进制流的请求，把文件存储在seleve端，这个图片就保存在服务端，当client需要展示图片的时候，需要在向seleve端发起请求，seleve端把文件地址返回给前端，实际上哪个地址还是seleve端文件服务器的地址，但会出现问题就是当高负载的时候，影响性能，因为每一张图片就是一个（静态）http请求，其实seleve端只是处理接口（api）逻辑（json数据）的没有必要去承担静态文件的压力，这时候要给他们分开，解耦合度，这时候就用到了fastdfs
fastdht，由于fastdfs本身不能对重复上传的文件进行去重，而fastdht可以做到去重，fastdht是一个高性能的分布式哈希系统，它是基于key，value存储的
fastdfs分布式文件存储
他有两个服务
（Tracker）
tracker就是负责调度用的，负责分配
（Storage）仓库，strorage就是负责存储系统的文件，图片，
当你存储在fastdfs是时候，tarcker会给你返回一个url
返回给seleve，seleve把完整的url（是在storage存的哪个地址）存到数据库，这个做的好处就seleve端动静分离开 





celery分布式任务队列（异步非堵塞机制）
实际上就相当去生产者和消费者模型
当我遇到多任务的时候，把同步的代码用celery帮助变成异步化，（提高性能，也提高的效率）他就相当于一个中间人的存在，他就是把发给他的任务异步执行，
架构分为3部分
（消息中间件）就相当于tracker调度（任务执行单元worker）就相当于服务员，（任务结果存储） 
对于brokers，官方推荐的rabbitmq和redis，这次我们用的是radditmq，因为性能上redis是数据库，不是专业消息中间件，
要想使用它就要修改源码了，因tonrdo里的asycr在3,6之前是随意命名的，在3,6以后就成关键字了





jwt（保证接口安全性的令牌（token）验证）（加密方式有base64，hs256因为可以反编译）
就是在登录的时候针对用户的信息做一个加密的窜，把这个窜就存储在客户端（客户端将存储在local storage里面，他就是一个客户端存储数据的库），客户端在请求接口的时候带着这个窜和服务端（解密）进行比对，jwt就主要是两个（payload）载荷客户端存储有效信息的地方，（signature）签名就是加盐，进行2次加密保证不被篡改

文件读写   和    网络请求io 线程

进程   计算的时候利用  tornado
并行
cpu

携程
多路复用





async声明一个函数是异步   await挂起



# Websocket信息推送

基于Websocket信息推送的研究与实现

摘　要： 传统的B/S应用由于HTTP协议的限制，无法实现服务器向浏览器推送信息。虽然可以通过一些技术手段变相实现信息的推送，但明显存在着各种不足。随着Websocket协议被W3C作为标准引入HTML5，各种浏览器开始支持Websocket。通过Websocket，浏览器和服务器之间可以建立一个双向的通信通道，从而实现实时的信息推送功能。在对Websocket进行了初步研究的基础上，通过对一个现实系统的升级，实现了基于Websocket的实时信息推送，达到预期效果。

websocket与http
WebSocket是HTML5出的东西（协议），也就是说HTTP协议没有变化，或者说没关系，但HTTP是不支持持久连接的（长连接，循环连接的不算）
首先HTTP有 1.1 和 1.0 之说，也就是所谓的 keep-alive ，把多个HTTP请求合并为一个，但是 Websocket 其实是一个新协议，跟HTTP协议基本没有关系，只是为了兼容现有浏览器的握手规范而已，有交集，但是并不是全部。
另外Html5是指的一系列新的API，或者说新规范，新技术。Http协议本身只有1.0和1.1，而且跟Html本身没有直接关系。。通俗来说，你可以用HTTP协议传输非Html数据

WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。
WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。
在 WebSocket API 中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。
现在，很多网站为了实现推送技术，所用的技术都是 Ajax 轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。
HTML5 定义的 WebSocket 协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。
浏览器通过 JavaScript 向服务器发出建立 WebSocket 连接的请求，连接建立以后，客户端和服务器端就可以通过 TCP 连接直接交换数据。
当你获取 Web Socket 连接后，你可以通过 send() 方法来向服务器发送数据，并通过 onmessage 事件来接收服务器返回的数据。
以下 API 用于创建 WebSocket 对象。

# Mysql的隔离级别

MySQL事务隔离级别
事务隔离级别   脏读   不可重复读   幻读 
读未提交（read-uncommitted）  是   是   是 
不可重复读（read-committed）   否   是   是 
可重复读（repeatable-read）   否   否   是 
串行化（serializable）   否   否   否 

# celery是什么？

Celery 是一个强大的 分布式任务队列 的 异步处理框架，它可以让任务的执行完全脱离主程序，甚至可以被分配到其他主机上运行。我们通常使用它来实现异步任务（async task）和定时任务（crontab）。我们需要一个消息队列来下发我们的任务。首先要有一个消息中间件，此处选择rabbitmq (也可选择 redis 或 Amazon Simple Queue Service(SQS)消息队列服务)。推荐 选择 rabbitmq 。使用RabbitMQ是官方特别推荐的方式，因此我也使用它作为我们的broker。

可以看到，Celery 主要包含以下几个模块：
任务模块 Task
包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列。
消息中间件 Broker
Broker，即为任务调度队列，接收任务生产者发来的消息（即任务），将任务存入队列。Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。
任务执行单元 Worker
Worker 是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。
任务结果存储 Backend
Backend 用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, redis 和 MongoDB 等。



# FastDFS

FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。
存储节点存储文件，完成文件管理的所有功能：就是这样的存储、同步和提供存取接口，FastDFS同时对文件的metadata进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value）方式表示，如：width=1024，其中的key为width，value为1024。文件metadata是文件属性列表，可以包含多个键值对。
跟踪器和存储节点都可以由一台或多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。
为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。
在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。
当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。



# Nginx的作用

nginx作用：保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击；负载均衡，通过反向代理服务器来优化网站的负载

# Docker

docker 可以聊命令 容器、镜像、仓库和一些遇到的坑，比如我们那会儿装机时无法挂载本地文件等 

Docker优势
更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。

Docker构架
Docker使用C/S架构，Client 通过接口与Server进程通信实现容器的构建，运行和发布。client和server可以运行在同一台集群，也可以通过跨主机实现远程通信。

Docker核心概念
镜像(image) Docker 镜像（Image）就是一个只读的模板。例如：一个镜像可以包含一个完整的操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。
仓库(repository) 仓库（Repository）是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。
容器(container) Docker 利用容器（Container）来运行应用。容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。
容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。

# Redis持久化

redis持久化的几种方式
1、快照（snapshots）
缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。
工作原理
Redis forks.
子进程开始将数据写到临时RDB文件中。
当子进程完成写RDB文件，用新文件替换老文件。
这种方式可以使Redis使用copy-on-write技术。
2、AOF
快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。
这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，Redis就不是一个合适的选择。Append-only文件模式是另一种选择。你可以在配置文件中打开AOF模式
RDB是Redis用来进行持久化的一种方式，是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时是将快照文件直接读到内存里。

# restful风格

restful是一种软件架构风格或者说是一种设计风格，并不是标准，它只是提供了一组设计原则和约束条件，主要用于客户端和服务器交互类的软件。
就像设计模式一样，并不是一定要遵循这些原则，而是基于这个风格设计的软件可以更简洁，更有层次，我们可以根据开发的实际情况，做相应的改变。
它里面提到了一些规范，例如：
1.restful 提倡面向资源编程,在url接口中尽量要使用名词，不要使用动词
2、在url接口中推荐使用Https协议，让网络接口更加安全 https://baidum/v1/mycss？page=3 （Https是Http的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL， 因此加密的详细内容就需要SSL（安全套接层协议））
3、在url中可以体现版本号 https://v1.bootcss.com/mycss
不同的版本可以有不同的接口，使其更加简洁，清晰
4、url中可以体现是否是API接口 https://baidum/api/mycss
5、url中可以添加条件去筛选匹配 https://baidum/v1/mycss？page=3
6、可以根据Http不同的method，进行不同的资源操作 （5种方法：GET / POST / PUT / DELETE / PATCH）
7、响应式应该设置状态码
8、有返回值，而且格式为统一的json格式
9、返回错误信息
10、返回结果中要提供帮助链接，即API最好做到接口文档

# Mysql主从同步

mysql主从同步的原理很简单，从库生成两个线程，一个I/O线程，一个SQL线程；i/o线程去请求主库 的binlog（二进制日志），并将得到的binlog日志写到relay log（中继日志） 文件中；主库会生成一个 log dump 线程，用来给从库 i/o线程传binlog；
SQL 线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致。

# 反向代理正向代理

反向代理和正向代理的区别就是：正向代理代理客户端，反向代理代理服务器。
　　反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。
正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。

# 插入排序

把数组分成两个部分，一个原始数组，一个新数组，默认新数组是排好序的，依次拿取原始数组放到新数组，第一个默认有序，第二个拿过来放到第一个元素后面，开始进行和前一个比较，大就不动，小就前移，直到不用动为止，依次拿取原始数组，依次类推，拿完为止，新数组就排好序了，这就是插入排序

# 归并排序

把原始列表对半分，直到全部分成单个元素，在两两合并，合并时小的在前大的在后，当元素多余一个时，两个合并的元素数组 在合并时分别有一个游标，谁小拿谁，依次拿完生成新的数组，知道各合为一体变成一个数组，排序完成  这就是归并排序



# 快速排序

每走访一遍把列表内最小的一个元素拿出来   ，没走放一边就依次把拿出来的元素放到新的列表内，直到把原始列表都拿完，新的列表就是排好序的列表

