jieba分词原理：
有一个词典，词典里面有每个词对应的权重，
有一句话，用这个词典进行分词，要求分完之后的每个词都必须在这个词典中出现过，目标是让这句话的权重最大。

jieba分词系统，主要实现三个模块：
1.分词
1.词性标注
3.关键词抽取

其中1.分词有三种模式（默认为精确模式）：
1.精确模式,试图将句子最精确地切开，适合文本分析。
2.全模式，把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义。
3.搜索引擎模式，在精确模式的基础上，对长词再词切分，提高召回率，适合用于搜索引擎分词。

jiaba分词还支持繁体分词和自定义分词，MIT授权协议。

jieba分词算法：
1.使用了基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能生成词情况所构成的有向无环图(DAG)，再采用了动态规划查找最大概率路径，找出基于词频的最大切分组合。
2.对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法。
3.基于Viterbi算法的词性标注。
4.分别基于tfidf和textrank模型抽取关键词




import jieba                       # 分词模块

result = jieba.lcut('我来自积云大学院,内蒙古自治区')               
print(result)				# .lcut()分词方法  返回的是一个列表

result = jieba.lcut('我来自积云大学院,内蒙古自治区',cut_all=False) 
print(result)				# cut_all=False 为精确模式：将句子最精确地切开（默认为False）

result = jieba.lcut('我来自积云大学院,内蒙古自治区',cut_all=True)  
print(result)				# cut_all=True  为全模式：把句子中所有的可以成词的词语都扫描出来

result = jieba.lcut_for_search('我来自积云大学院,内蒙古自治区')    
print(result)				# .lcut_for_search()搜索引擎模式分词方法：对长词再次切分，提高召回率

# 自定义分词
jieba.load_userdict('071.txt')          # .load_userdict()加载用户词典方法
result = jieba.lcut('无妻徒刑,堂葫芦')
print(result)



# 绘制词云图

import numpy as np                         # 处理多维数组（矩阵）模块
from PIL import Image                      # 图片库中的图像模块
from wordcloud import WordCloud            # 词云中的词云模块
import matplotlib                          # 绘图库模块
from matplotlib import pyplot as plt       # 绘图库中的绘图命令模块

matplotlib.rcParams['font.sans-serif'] = 'SimHei'       # 设置字体为SimHei黑体 显示中文


f = open('072.txt','rb')                                # 读二进制文件
content = f.read()                                      # 读取整个上传文件的内容
words = jieba.lcut(content)                             # 分词
newcontent = ' '.join(words)                            # 将分词以空格隔开
print(newcontent)

backgroud_Image = np.array(Image.open("073.jpg"))       # Image.open() 打开图片方法,并将图片转换为ndarray类型
wc = WordCloud(                                         # WordCloud()  初始化词云方法
    background_color='black',                           # background_color 设置背景颜色，与图片的背景色相关
    mask=backgroud_Image,                               # mask             设置背景图片
    font_path='C:\Windows\Fonts\SimHei.ttf',            # font_path        显示中文，可以更换字体
    max_words=200,                                      # max_words        设置最大显示的字数
    stopwords={'语言'},                                 # stopwords        设置停用词，停用词则不再词云图中表示
    max_font_size=150,                                  # max_font_size    设置字体最大值
)
wordcloud=wc.generate(newcontent)                       # .generate()生成词云图方法
	# wordcloud=wc.generate('qwe,asd')  		# 只能是字符串，且字符串间是分开的  

plt.figure(figsize=(40,40))                             # 初始化一张画布
plt.imshow(wordcloud)                                   # plt.imshow() 显示待处理的图像负责对图像进行处理
plt.axis('off')                                         # plt.axis()   是否显示坐标轴
plt.show()                                              # 显示图片  将plt.imshow()处理后的显示出来。








