建模流程
数据-_分析_--预处理--分割--选择模型--预测数据--模型评估--重新选择模型

data		内容数据(ndarray类型)
feature_names	特征名称(列名)
target		标签(行数据标签)
data.shape	数据形状


# 设置随机种子
import numpy as np                                          # 处理多维数组（矩阵）模块
np.random.seed(10)                                                    # 随机种子(固定随机数的作用)


# 加载数据集
from sklearn import datasets                                # 数据集模块    datasets中包含了众多数据集
hous = datasets.load_boston()                                         # 加载波士顿房价'数据集'
hous                                                                  # 查看数据集
dataset_X = hous.data                                                 # data   取出数据集的特征数据(列)
dataset_Y = hous.target                                               # target 取出数据集对应的标签(行)


# 分割数据集
from sklearn.model_selection import train_test_split        # 分割数据集模块
	（用于将矩阵随机划分为训练子集和测试子集，并返回划分好的训练集测试集数据样本和训练集测试集标签）
train_X,test_X,train_y,test_y = train_test_split(dataset_X,dataset_Y,test_size=0.2)
                                           # train 训练 test 测试 test_size 设置训练集分割比例
                                           # train_X 0.8数据,test_X 0.2数据,train_y 0.8标签,test_y 0.2标签

# 建模 
from sklearn.tree import DecisionTreeRegressor              # 决策树的回归模型模块
	（回归是对连续变量做决策树【取的是某区间(列)内的某个值】用于预测平均值）
dtReg = DecisionTreeRegressor()                 # 获取一个回归器对象  参数：max_depth=5 设置树的最大深度


# 训练数据 
dtReg.fit(train_X,train_y)                      # 拿出训练数据0.8 训练标签0.8 训练决策树回归模型
						（fit训练方法：可以理解为一个训练过程）

# 预测数据
y_pre_test = dtReg.predict(test_X)              # 再使用训练后的模型 预测 测试数据0.2 得出对应的0.2标签 							(predict预测方法：返回预测标签)
print('预测的标签值：')
print(y_pre_test)                               # 预测的标签值0.2
print('真实的标签值：')
print(test_y)                                   # 真实的标签值0.2


# 决策树数据可视化关系图
from sklearn import tree                                    # 决策树模块
import graphviz                                             # 图形绘制工具模块 用于显示文件数据
dot_data = tree.export_graphviz(dtReg,out_file=None,filled=True)      
						# 导入训练后的模型中的节点信息到文件
	（tree.export_graphviz()方法：设置决策树的图形 out_file=None 设置文件名 filled=True 填充颜色）    
graph = graphviz.Source(dot_data)               
	（graphviz.Source()方法：设置图形的源文件  将决策树节点信息导入进文件）
graph.render('tree',view=False)                                       
	（.render()方法：渲染决策树，参数：图片与文件名 view=True 打开图 在同级目录下生成tree.pdf图片文件）


# 当没有配置环境变量时puth报错，解决方案：自行填写它的绝对路径
# import os
# os.environ["PATH"] += os.pathsep + '绝对路径'


# 树的可视化图形解释
# X[索引值] <= 9.95    X 代表x轴的数据特征(列)的值 
# mse = 73.2779       均方误差值 越大越离散(坏) 越小越紧密(好) 用于评测回归模型的好坏【mae是均方绝对误差值】
# samples = 404       数据样本数量
# value = 22.1517     最终得出的结果标签值



# 回归模型的评估
from sklearn import metrics                               # 模型评估模块
mse = metrics.mean_squared_error(y_pred=y_pre_test,y_true=test_y)     
					# 测试值与真实值对比计算出均方误差，MSE越小说明模型越准确
					# metrics.mean_squared_error()方法：计算在测试数据上的均方误差MSE
					（它每次的值是随机变化的 需要设置随机种子来固定它的值）
print('均方误差值：')
print(mse)                                                            
     



# 弱分类器：每一颗树就是一个弱分类器
# 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。（优先预测被分类错误的'样本'）
# 加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在表决中起较大作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。（优先使用误差率小的'弱分类器'）


# 优化决策树
from sklearn.ensemble import AdaBoostRegressor            # 集成模块 的算法 AdaBoost(提升算法)Regressor回归
                                   # 使用集成算法：可以生成多颗决策树，通过将多个弱回归器组合成一个强回归器
dtReg = DecisionTreeRegressor(max_depth=5)         
					# 必须重新获取一个回归器对象，为了把训练任务交给adaboost
adaBoostRe = AdaBoostRegressor(dtReg,n_estimators=400)                
					# 参数：给出一个弱回归器，n_estimators 设置最大弱回归器的数量
# 训练数据
adaBoostRe.fit(train_X,train_y)         # 重新拿出训练数据0.8 训练标签0.8 训练 决策树回归模型

# 预测数据
y_pre_test = adaBoostRe.predict(test_X) # 重新再使用训练后的模型 预测 测试数据0.2 得出对应的0.2标签
print('***********************************************************************************')
print('优化后预测的标签值：')
print(y_pre_test)                                                    # 优化后预测的标签值0.2
print('真实的标签值：')
print(test_y)                                                        # 真实的标签值0.2
print('优化后再次测试数据上的均方误差MSE：')
print(metrics.mean_squared_error(y_pred=y_pre_test,y_true=test_y))   # 优化后再次测试数据上的均方误差MSE




